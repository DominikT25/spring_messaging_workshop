package com.workshop.kafka.consumer;

import com.workshop.kafka.metrics.MetricsService;
import com.workshop.kafka.model.WorkshopMessage;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Service;

import java.util.Map;
import java.util.Random;
import java.util.concurrent.ConcurrentHashMap;

/**
 * Consumer service pro zpracov√°n√≠ zpr√°v z Kafka.
 * Implementuje retry logiku s exponential backoff a DLQ.
 */
@Service
@Slf4j
@RequiredArgsConstructor
public class MessageConsumer {

    private final MetricsService metricsService;
    private final KafkaTemplate<String, WorkshopMessage> kafkaTemplate;
    private final Random random = new Random();
    private final Map<String, Integer> retryCountMap = new ConcurrentHashMap<>();
    
    private int processedCount = 0;

    @Value("${workshop.kafka.dlq-topic}")
    private String dlqTopicName;

    @Value("${workshop.kafka.max-retries:3}")
    private int maxRetries;

    @Value("${workshop.kafka.simulate-failures:false}")
    private boolean simulateFailures;

    @Value("${workshop.kafka.failure-rate:0.1}")
    private double failureRate;

    /**
     * Listener pro hlavn√≠ topic.
     */
    @KafkaListener(topics = "${workshop.kafka.topic}", groupId = "workshop-consumer-group")
    public void receiveMessage(@Payload WorkshopMessage message,
                              @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
                              @Header(KafkaHeaders.OFFSET) long offset,
                              Acknowledgment acknowledgment) {
        
        long startTime = System.nanoTime();
        String messageKey = partition + ":" + offset;
        
        try {
            // Zpracov√°n√≠ zpr√°vy
            processMessage(message);
            
            // ACK - √∫spƒõ≈°n√© zpracov√°n√≠
            acknowledgment.acknowledge();
            
            // Odstranƒõn√≠ z retry mapy
            retryCountMap.remove(messageKey);
            
            long latency = System.nanoTime() - startTime;
            metricsService.recordMessageConsumed(latency);
            
            processedCount++;
            if (processedCount % 100 == 0) {
                log.info("  Zpracov√°no: {} zpr√°v", processedCount);
            }
            
        } catch (Exception e) {
            // Z√≠sk√°n√≠ retry poƒçtu
            int currentRetryCount = retryCountMap.getOrDefault(messageKey, 0);
            
            if (currentRetryCount < maxRetries) {
                // Retry s exponential backoff
                retryCountMap.put(messageKey, currentRetryCount + 1);
                
                long backoffMs = (long) Math.pow(2, currentRetryCount) * 1000;
                log.warn("‚ö† Chyba zpracov√°n√≠ zpr√°vy {} (pokus {}/{}): {}. Backoff: {} ms", 
                        message.getId(), currentRetryCount + 1, maxRetries, e.getMessage(), backoffMs);
                
                try {
                    Thread.sleep(backoffMs);
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                }
                
                // NEPOTVRZUJEME offset - zpr√°va bude znovu naƒçtena
                
            } else {
                // P≈ôesun do DLQ
                log.error("‚úó Zpr√°va {} p≈ôesunuta do DLQ po {} pokusech", 
                        message.getId(), maxRetries);
                
                sendToDLQ(message, e.getMessage());
                
                // ACK offset po p≈ôesunu do DLQ
                acknowledgment.acknowledge();
                retryCountMap.remove(messageKey);
                metricsService.recordMessageFailed();
            }
        }
    }

    /**
     * Listener pro DLQ topic - pouze logov√°n√≠.
     */
    @KafkaListener(topics = "${workshop.kafka.dlq-topic}", groupId = "workshop-dlq-consumer-group")
    public void receiveDLQMessage(@Payload WorkshopMessage message,
                                  Acknowledgment acknowledgment) {
        
        log.info("üì• DLQ: P≈ôijata zpr√°va {} do Dead Letter Queue", message.getId());
        
        // ACK zpr√°vy v DLQ
        acknowledgment.acknowledge();
    }

    /**
     * Zpracov√°n√≠ zpr√°vy s mo≈ænost√≠ simulace chyb.
     */
    private void processMessage(WorkshopMessage message) throws Exception {
        // Simulace n√°hodn√Ωch chyb
        if (simulateFailures && random.nextDouble() < failureRate) {
            throw new RuntimeException("Simulovan√° chyba zpracov√°n√≠");
        }
        
        // Simulace zpracov√°n√≠
        Thread.sleep(1);
        
        log.debug("‚úì Zpracov√°na zpr√°va: {}", message.getId());
    }

    /**
     * Odesl√°n√≠ zpr√°vy do DLQ.
     */
    private void sendToDLQ(WorkshopMessage message, String error) {
        try {
            message.setContent(message.getContent() + " [ERROR: " + error + "]");
            message.setRetryCount(maxRetries);
            
            kafkaTemplate.send(dlqTopicName, "dlq-" + message.getId(), message);
        } catch (Exception e) {
            log.error("Chyba p≈ôi odes√≠l√°n√≠ do DLQ: {}", e.getMessage());
        }
    }

    public int getProcessedCount() {
        return processedCount;
    }

    public void resetProcessedCount() {
        this.processedCount = 0;
        this.retryCountMap.clear();
    }
}

